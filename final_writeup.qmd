---
title: "STA5073Z Assignment 2"
author: "Susana Maganga, Ndivhuwo Nyase and Puja Pande"
format: pdf
editor: visual
toc: true
number-sections: true
execute: 
  echo: false
---

## Introduction

A State of Nation Address (SONA) is a speech given by the President of South Africa in which the president reports on the status of the nation. It functions as an annual report that include political and socio-economic topics. These include but not limited to topics surrounding the nation's budget, economy, news, agenda, progress, achievements and the president's priorities and legislative proposals. The SONA gives us an idea of broader political landscape and socio-economic issues and challenges that are plauging the country. At the same time, it also reflect on the achievements and growth and progress the country has made in the past year. Furthermore, it provides us with a direction and understanding of the countries plans. With that being said, to comprehensively analyze the history of the SONA speeches will provide us extensive perspective and viewpoint of the struggles and triumph over the course of South Africa. In this assignment, we aim to provide that perspective and viewpoint from a computational approach. We will utilize sentiment analysis and topic modelling techniques to quantified the emotional tone of each president and reoccurring topics that will provide context and understanding to the broader socio-political and economic environment of South Africa. More specifically, utilizing sentiment analysis and a topic modelling technique called Latent Dirichlet Allocation (LDA) to analyze the SONA speeches from 1994 and 2022. Sentiment analysis refers to the use of natural language processing (NLP), text analysis, computational linguistics, to identify, extract, quantify, and study affective states and subjective information. Furthermore, Topic modelling is a statistical and unsupervised learning technique to identify and discover topics within a collection of text or documents. It is commonly used to classify documents and discover hidden semantic properties in a corpus of text. A related study involves exploring sentiment and topics from Philippine President in the SONA from John Miranda and Rex P. Bringula (2021). The study showcased the SONAs generally expressed positive sentiments while the lowest negative sentiment was during the martial law period in 1974. Furthermore, another related study includes Mining Tourist's Perception toward Indonesia Tourism Destination. Results shows that Joy is the most prominent emotion accompanying visitors' experiences (Herry Irawan, Riefvan Achmad (2019)). The relevant work showcases that researchers have found significant results when investigating documents of texts with regards to evaluating emotive content or extracting common themes and topics.

```{r setup , include = FALSE, message=FALSE, echo=FALSE}
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")

# Loading packages
library(tidyverse)
library(tidytext)
library(textdata) 
library(stringr)
library(lubridate)
library(devtools)
library(kableExtra)

# Load data
source("https://raw.githubusercontent.com/ClosestNeighbours/DS4I-Project-2/LDA---Puja/editted_sona_first_steps.R")
sona$date[36] <- "09-02-2023"

# Load dictionaries
load(url("https://raw.githubusercontent.com/ClosestNeighbours/DS4I-Project-2/Sentiment-Analysis/dsfi-lexicons.Rdata"))

# Preprocess: tokenise & remove stop words
sona$president_13 <- as.factor(sona$president_13)
sona$year <- as.numeric(sona$year)
sona$date <- as.Date(sona$date,format = "%d-%m-%Y")

tidy_sona <- sona %>% unnest_tokens(word, speech, token = "words", to_lower = T) %>% 
  filter(!word %in% stop_words$word)

# Join bing lexicon
sona_sentiment <- tidy_sona %>% 
  left_join(bing, by = "word") %>%
  rename(bing_sentiment = sentiment) %>%
  mutate(bing_sentiment = ifelse(is.na(bing_sentiment), 'neutral', bing_sentiment)) %>% 
  mutate(bing_sentiment = ifelse(bing_sentiment == "oppressed", "negative", bing_sentiment)) %>%
  mutate(bing_sentiment = ifelse(bing_sentiment %in% c("honour", "hope"), "positive", bing_sentiment))         

# Join nrc lexicon
sona_sentiment <- sona_sentiment %>% 
  left_join(nrc, by = "word", relationship = "many-to-many") %>%
  rename(nrc_sentiment = sentiment) %>%
  mutate(nrc_sentiment = ifelse(is.na(nrc_sentiment), 'neutral', nrc_sentiment))
```

# Data and Methods

## Data Collection

As the aim of this project was to analyse State of the Nation (SONA) speeches delivered by the Presidents of South Africa, the data used for this project were SONA speeches from 1994 through to 2023. These were accessed from the South African Government website (*https://www.gov.za/state-nation-address*) and include speeches from before and after the election of six presidents: FW de Klerk, Nelson Mandela, Thabo Mbeki, Kgalema Motlanthe, Jacob Zuma and the current president, Cyril Ramaphosa. Overall, 36 speeches were analysed. How these speeches were analysed will be explained in the sections to come.

## Data Cleaning and Preprocessing

In order to analyse and model the SONA data, it had to be cleaned and preprocessed first. The .txt files were first read into R where they were all added to a single dataframe. The information regarding the date and year in which the speech was delivered as well as the president delivering the speech were extracted and adding as columns to the dataframe. In addition to this, the dates were all formatted to the same format, all the punctuation was removed and the words in the speeches were all converted to lowercase. The text was also cleaned to remove the dates that appear at the beginning/towards the beginning of the speeches. Lastly, all numbers were removed for the latent Dirichlet allocation (LDA).

The speeches were then converted to a 'tidy' format whereby the data were then processed so that all variables were in columns, all observations are in rows and every value is in a cell where a cell may only have one value. During this process of converting the speeches to a 'tidy' format, the process of tokenisation was also implemented which is the process of taking a text string, such as each individual speech and decomposing it into chunks which in this case were words. Essentially, the speeches were broken down into words and converted to a format where each observation only consisted of one word. After this was done, stop words or words that occur commonly, were removed from the 'tidy' dataset so that these would not add noise while analysing the data.

After the data had been cleaned and pre-processed, exploratory data analysis was conducted on the data and sentiment analysis as well as LDA was carried out on the speeches and words.

## Exploratory Data Analysis

Before conducting any in-depth analysis of the data through sentiment analysis and LDA, exploratory data analysis (EDA) was performed on the data in order to gain a better understanding of the data.

First, the number of words per president were counted. The most number of words from a president was from Mbeki with 5622 words followed by Zuma with 5258, Ramaphosa with 4753, Mandela with 4311 and finally Motlanthe and de Klerk with 1631 and 431, respectively. The lower number of words for Motlanthe can be attributed to the fact that he was only president for roughly six month and hence participated in only one SONA. For de Klerk, this may have been because this was the end of the Apartheid regime for which he was the last president. Furthermore, the top ten most used words across all speeches were as follows: government, south people, country, national, development, africa, public, economic, ensure. All of which one would expect to hear given the nature of the SONA speeches.

Lastly, the top 15 words spoken by each president are summarised in the figures below. DONT KNOW HOW TO ADD PLOTS YET.

The first figure summaries the top 15 words spoken by president while the second figure shows the same with the exclusion of the words: government, people, south, africa, african. These are widely used by most presidents and may not be valuable in indicating trends with regards to the most words used. It can be seen that the words associated with de Klerk are focused around freedom and the transitioning of South Africa from an Apartheid state to a democratic one through words such as: 'constitution', 'freedom' and 'transitional'. Mandela's most used words 'development' and 'economic' may be attributed to the re-development of South Africa as a democratic state but words such as 'crime' and 'security' indicate a sense of unsafety. Mbeki's words seem to be more related to the economy and development while Motlathe's address similar issues with the addition of poverty. Ramaphosa's words are even more so centered around economic development and businesses which may be due to the effects of the Covid-19 pandemic during his time as president. Lastly, Zuma's words follow a similar economic and development trend to the rest with the addition of water as the Western Cape droughts occurred during his time as president.

## Sentiment Analysis

Sentiment analysis is a text mining technique that aims to extract the thoughts and feelings of script to determine their polarity, i.e. positive, negative or neutral. Three approaches are available to conduct sentiment analysis: supervised, lexicon-based and hybrid. The supervised method utilities machine learning algorithms to train the classifier. It is superior in performance to the lexicon-based method, however it requires a substantial amount of labelled data. Lexicon-based sentiment analysis uses sentiment lexicons (dictionaries) to describe polarity. This method is more computationally efficient, but the results may vary depending on the lexicon and domain. A word may be subjective or objective depending on the context, e.g. in the clause "crude oil", this is an objective use of the word crude; when it is used as "crude language", it is now subjective and has a negative sentiment. Dealing with negation and sarcasm is also a challenge with this approach. The hybrid method is an amalgamation of the supervised and lexicon-based methods (Sadia et al, 2018).

This section will discuss the results obtained from employing the lexicon-based approach to determine the outlook of the South African Presidents. The *bing* and *nrc* lexicons were explored. In the instance that a word was not in the lexicon, the default label was set to "neutral". The *bing* lexicon was developed by Minqing Hu and Bing Liu as the *Opinion Lexicon*. It comprises of 6786 words, where 2005 are "positive" and 4781 are "negative".\
The *nrc* lexicon has 13872 words and incorporates more sentiments in addition to positive and negative: anger, anticipation, disgust, fear, joy, sadness, surprise and trust.

```{r nrc table, message=FALSE, echo=FALSE}
kbl(as.data.frame(table(nrc$sentiment)), col.names = c("Category", "No. of Words"), caption = "Words in the nrc lexicon") %>% kable_styling(latex_options = "HOLD_position")
```

## Latent Dirichlet Allocation

LDA is a popular topic modelling model which allows one to better understand hidden themes in a collection, classify the documents into these themes and summarise the documents. In an LDA model, each document is comprised of various words as is each topic. This document being referred to is achieved after the 'tidy' data is converted to a 'DocumentTermMatrix'.

In an LDA model, one of the hyperparameters is $k$. If there are $k$ topics, each topic from the document is generated from a distribution with different probabilities. So if $z_{km}$ is the $k$th topic in the $m$th document, it takes a value between 1 and $K$. \$\$ z\_{km} \sim Multinomial(\theta\_m)

\$\$ where $\theta_m = (\theta_{m1}, \theta_{m2}, ..., \theta_{mk})'$ is the topic probability.

Once a topic has been decided upon, words are organised around it. So if $w_{mn}$ is the $n$th word used in the $m$th document, it would take a value between 1 and $V$ with $V$ being the total number of unique words used in all the documents. The equation below shows how a word is generated: \$\$ w\_{mn}\|z\_{km} \sim Multinomial(\beta\_k)

\$\$ where $\beta_k = c(\beta_{k1}, \beta_{k2}, ..., \beta_{kV})'$ is the probability that a word is picked given the topic k is selected.

Lastly, it is important to get $\theta$ and $\beta$ values as these represent the distribution of topics for a particular document and the distribution of words within each topic. The assumption is that both are generated from a Dirichlet distribution. For topic probability: $$
\theta_m \sim Dirichlet(\alpha)
$$ And for word probability:

$$
\beta_m \sim Dirichlet(\delta)
$$

In the context of this project, first the 'tidy' data was converted to a 'DocumentTermMatrix' to which the LDA model was applied to. First, the top 20 most used words overall were removed from the dataset as a means of pruning the data. A grid search for the best $k$ hyperparameter was conducted using the metric of coherence values. This measures the relative distance between words within a topic and suggested that a $k = 17$ be used. However, upon inspection of these topics, there was a lot of overlap. The next highest values were for greater than 17. Finally, a $k=9$ was chosen as the topics were clear and there was little overlap. An LDA model was created on the overall data as well as for each president. For each individual president, a value of $k=2$ was chosen.

## Use of Large Language Models - may need to move section

While not an aim of this project, it was a requirement that we experiment with the use of a large language model such as ChatGPT to assist with the assignment. While using basic search engines to help with coding and writing are helpful, ChatGPT is more efficient in providing specific answers to some questions as it can provide textual context, conversational interactions and can remeber previous questions and refer to them.

In terms of coding, ChatGPT was useful in assisting with code for plot parameters as well as the syntax for certain elements of this document e.g. the equations. However, it sometimes produced code that was not correct or used incorrect functions not belonging to the packages specified. In this case, the error produced in R was inputted back into the conversation and it was almost always able to provide the correct code, albeit after many tries sometimes. The inputs, however, into the conversation had to be very specific to provide the correct context for ChatGPT and to avoid unnescesy back-and-forth on simple questions stemming from a lack of context. One big plus was ChatGPT's ability to remeber previous questions in a conversation so that once the context had been specified, it could draw from previous questions to answer future ones. Overall, from a coding point of view, this large language model performed decently but there was often a lot of promtping that had to be done.

In terms of understanding specific terminology and better understand the models, it was able to provide a decent summary of these which in conjuction with other resurces helped with the understadning of these models.

Lastly, in terms of writing -\> add something about paraphrasing/simplification?

An example of applying ChatGPT to generate code was requesting for a function that extract sentences containing specific bigrams. Before providing much context, the response given was steps to manually do it in a programming language. When prompted for code, ChatGPT assumed that it was being done in Python. To provide context, the programming language as well as the structure of the tidy data was provided as a response. R code was subsequently returned and it worked exactly as expected. Comments were also provided to guide the user.

```{r ChatGPT Bigram Code, echo=TRUE, eval=FALSE}
# Define the specific bigram
specific_bigram <- "specific bigram"  # Replace with your desired bigram

# Initialize a list to store sentences containing the bigram
sentences_with_bigram <- character(0)

# Search for the bigram in each sentence
for (sentence in sona_sentences$sentence) {
  if (grepl(specific_bigram, sentence, ignore.case = TRUE)) {
    sentences_with_bigram <- c(sentences_with_bigram, sentence)
  }
}

# Print or manipulate the extracted sentences
print(sentences_with_bigram)
```

# Results

## Sentiment Analysis

### Word-Level Analysis

In this subsection, a word-level analysis will be conducted. The top 20 positive and negative words in the speeches as a whole, as well as a breakdown per president using the *bing* lexicon are presented below.

```{r Top 20 Positive Words, message=FALSE, echo=FALSE, fig.align='center', fig.show="hold", out.width="60%", fig.cap="Top 20 positive words used in speeches based on the bing lexicon"}
sona_sentiment %>%
  filter(bing_sentiment == 'positive') %>%
  count(word) %>%
  arrange(desc(n)) %>%
  filter(rank(desc(n)) <= 20) %>%
  ggplot(aes(reorder(word,n),n)) + 
  geom_col(fill="slateblue3") + coord_flip() +
  labs(title = "Top 20 Positive Words", x = "Word", y = "Count")
```

```{r Top 10 Positive Words by President, message=FALSE, echo=FALSE, fig.align='center', fig.show="hold", out.width="60%", fig.cap="Top 20 positive words by president based on the bing lexicon"}
top_pos_pres <- sona_sentiment %>%
  filter(bing_sentiment == "positive") %>%
  count(president_13, word) %>%
  group_by(president_13) %>%
  filter(rank(desc(n)) <= 10)

top_pos_pres %>%
  ggplot(aes(reorder(word, n), n)) +
  geom_col(fill = "skyblue") +
  facet_wrap(~president_13, scales = "free") +
  coord_flip() +
  labs(title = "Top 10 Positive Words per President", x = "", y = "Frequency") 
```

Overall, the word **improve** was the most used positive word in all of the speeches. This is also true when the words are grouped by president, except for deKlerk, whose most used word was **freedom**. Other recurring words include **progress** and **peace**/**peaceful**.

```{r Top 20 Negative Words, message=FALSE, echo=FALSE, fig.align='center', fig.show="hold", out.width="60%", fig.cap="Top 20 negative words used in speeches based on the bing lexicon"}
sona_sentiment %>%
  filter(bing_sentiment == 'negative') %>%
  count(word) %>%
  arrange(desc(n)) %>%
  filter(rank(desc(n)) <= 20) %>%
  ggplot(aes(reorder(word,n),n)) + geom_col(fill="slateblue3") + coord_flip() + 
  labs(title = "Top 20 Negative Words", x = "Word", y = "Count")
```

```{r Top 10 Negative Words by President, message=FALSE, echo=FALSE, fig.align='center', fig.show="hold", out.width="60%", fig.cap="Top 20 negative words by president based on the bing lexicon"}
top_neg_pres <- sona_sentiment %>%
  filter(bing_sentiment == "negative") %>%
  count(president_13, word) %>%
  group_by(president_13) %>%
  filter(rank(desc(n)) <= 10)

top_neg_pres %>%
  ggplot(aes(reorder(word, n), n)) +
  geom_col(fill = "skyblue") +
  facet_wrap(~president_13, scales = "free") +
  coord_flip() +
  labs(title = "Top 10 Negative Words per President", x = "", y = "Frequency") 
```

**Poverty**, **crime** and **corruption** were the most commonly used negative words. They also appeared in the breakdown by president; except for deKlerk, who did not have any of these three words in his top ten negative words. deKlerk commonly used the words **violent**, **illegal** and **discrimination**.

### Sentiment-Level Analysis

The general feeling of the speeches, broken down by sentiments, for each president were examined using both the *nrc* and *bing* lexicons. The neutral words were excluded, as they dominate over the other sentiments.

```{r Sentiment Prop by President, message=FALSE, echo=FALSE, fig.align='center', fig.show="hold", out.width="60%", fig.cap="Proportion of positive to negative words by president based on the bing lexicon"}
sentiment_prop <- sona_sentiment %>%
  group_by(president_13, bing_sentiment) %>%
  summarize(word_count = n()) %>% 
  filter(!bing_sentiment == "neutral") %>% 
  mutate(proportion = word_count / sum(word_count))

ggplot(sentiment_prop, aes(x = president_13, y = proportion, fill = bing_sentiment)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Proportion of Positive to Negative Words by President",
    x = "President",
    y = "Proportion"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_color_discrete(name = "Sentiment", labels = c("Negative", "Positive")) 
```

The proportions of positive to negative words do not seem to differ by a large amount. However, the plots indicate that **Zuma**, **Mbeki** and **Mandela** expressed relatively more positive sentiments in comparison to the other presidents. To further delve into the presidents' attitudes, the more comprehensive *nrc* lexicon was applied.

```{r Sentiment Bars by President (nrc), message=FALSE, echo=FALSE, fig.align='center', fig.show="hold", out.width="60%", fig.cap="Proportion of positive to negative words by president based on the bing lexicon"}
sona_sentiment %>%
  add_count(president_13, name = "n_words") %>%
  group_by(president_13, nrc_sentiment) %>%
  summarize(prop = n() / first(n_words)) %>% ungroup() %>%
  filter(nrc_sentiment != "neutral") %>%  
  ggplot(aes(nrc_sentiment, prop, fill = nrc_sentiment)) +
  geom_bar(stat = "identity") +
  facet_wrap(~president_13, scales = "free") +
  labs(title = "Sentiment Proportions by President", fill = "Sentiment", x = "Proportion", y = "Sentiment") +
  coord_flip() 
```

From the plots, it can be observed that, besides *negative* and *positive* sentiments, prevalent themes include *trust* and *anticipation*. To gain some insight of the words specifically associated with these themes, the top 2 words associated with *trust* or *anticipation* for each president are presented in a table below.

```{r Anticipation and Trust Words, message=FALSE, echo=FALSE}
senti_table <- sona_sentiment %>%
    filter(nrc_sentiment %in% c("trust", "anticipation")) %>%
    group_by(president_13, word, nrc_sentiment, bing_sentiment) %>%
    summarise(word_count = n()) %>%
    arrange(president_13, desc(word_count)) %>%
    group_by(president_13) %>%
    top_n(2, word_count) %>%
    ungroup()

kbl(as.data.frame(senti_table[,-5]), col.names = c("President", "Word", "nrc", "bing"), caption = "Top 2 words by president associated with either anticipation or trust according to the nrc lexicon") %>% kable_styling(latex_options = "HOLD_position")
```

Most of the words associated with trust or anticipation in the *nrc* lexicon are categorised as "neutral" in the *bing* lexicon. This highlights the variability that different dictionaries can yield in an analysis. Additionally, it is important to note that due to the multi-level nature of words in the *nrc* lexicon, some words are associated with more than one sentiment, such as **continue**.

Changes of the sentiments over time were also investigated. Since there is a large number of neutral words, these were excluded from the analysis. Line plots with corresponding smoothed lines were generated to assess any shifts in positive or negative sentiments.

To assess whether the shifts are statistically significant, a logistic regression model was employed. Logistic regression is a modelling technique, based on regression, in which the dependent variable is binary. This is an appropriate model to use because the dependent variable has a binary outcome: *positive* or *negative*.

```{r Trends over Time, message=FALSE, echo=FALSE, fig.align='center', fig.show="hold", out.width="60%", fig.cap="Proportion of positive to negative words by president based on the bing lexicon"}
sentiments_time <- sona_sentiment %>%
  group_by(date, bing_sentiment) %>%
  summarize(n = n()) 

sentiments_time <- sentiments_time %>% 
  left_join(sentiments_time %>% 
              group_by(date) %>% 
              summarise(total = sum(n))) %>%
  mutate(freq = n/total) 

sentiments_time %>% filter(bing_sentiment != 'neutral') %>%
  ggplot(aes(x = date, y = freq, colour = bing_sentiment)) +
  geom_line() + 
  geom_smooth(aes(colour = bing_sentiment)) +
  labs(title = "Sentiments over Time", fill ="Sentiment", x = "Date", y = "Frequency") +
  scale_color_discrete(name="Sentiment", labels = c("Negative", "Positive"))
```

```{r Fit Binomial GLM, message=FALSE, echo=FALSE}
glm_model <- glm(as.factor(bing_sentiment) ~ date, data = subset(sentiments_time, bing_sentiment != "neutral"), family = "binomial")

glm_summary <- summary(glm_model)

kbl(as.data.frame(glm_summary$coefficients), caption = "Results from applying logistic regression") %>% kable_styling(latex_options = "HOLD_position")
```

From the plot, it appears that there has generally been a decline in negative sentiment over the years.\
The p-values obtained from the logistic regression, however, are above the traditional threshold of 0.05, indicating that there was no significant decrease in the proportion of negative sentiments over time.

### Bigrams Analysis

An n-gram is a sequence of *n* words in a text. Bigrams, in particular, are pairs of words that are adjacent to each other. Certain words, such as "not" change the meaning of the subsequent word by negating it. It is therefore important to consider this when conducting sentiment analysis.

This subsection section will explore the most common positive and negative bigrams in the speeches using the *bing* dictionary. To determine the net sentiment of a bigram, positive words are assigned a value of 1 and negative words are assigned a value of -1. Words that are preceded by a negation word ('not', 'no', 'never', 'without' or 'anti') had their sentiment reversed. During the analysis, a few of the labels given to words in the *bing* dictionary did not align with this context and were thus adjusted. Consequently, 'honour' and 'hope' were changed from *neutral* to *positive*. The word 'oppression' was reclassified from *neutral* to *negative*.

```{r Dealing With Negation, message=FALSE, echo=FALSE}
# Create bigrams and add sentiment for each word
bigrams_separated  <- sona %>%
  mutate(speech = str_replace_all(speech, replace_reg, '')) %>%
  unnest_tokens(bigram, speech, token = 'ngrams', n = 2) %>%
  separate(bigram, c('word1', 'word2'), sep = ' ')

bigrams_separated <- bigrams_separated %>% 
  left_join(bing, by = c(word1 = 'word')) %>%
  rename(sentiment1 = sentiment) %>%
  mutate(sentiment1 = ifelse(is.na(sentiment1), 'neutral', sentiment1)) %>%
  mutate(sentiment1 = ifelse(sentiment1 == "oppressed", "negative", sentiment1)) %>%
  mutate(sentiment1 = ifelse(sentiment1 %in% c("honour", "hope"), "positive", sentiment1)) %>%         
  left_join(bing, by = c(word2 = 'word')) %>%
  rename(sentiment2 = sentiment) %>%
  mutate(sentiment2 = ifelse(is.na(sentiment2), 'neutral', sentiment2)) %>%
  mutate(sentiment2 = ifelse(sentiment2 == "oppressed", "negative", sentiment2)) %>%
  mutate(sentiment2 = ifelse(sentiment2 %in% c("honour", "hope"), "positive", sentiment2)) %>%         
  select(date, word1, word2, sentiment1, sentiment2, everything())

# Reverse the sentiment if preceding word is negative
negation_words <- c('not', 'no', 'never', 'without', 'anti')

bigrams_separated <- bigrams_separated %>%
  
  # create a variable that is the opposite of sentiment2
  mutate(opp_sentiment2 = recode(sentiment2, 'positive' = 'negative',
                                 'negative' = 'positive',
                                 'neutral' = 'neutral')) %>%
  
  # reverse sentiment2 if word1 is a negation word
  mutate(sentiment2 = ifelse(word1 %in% negation_words, opp_sentiment2, sentiment2)) %>%
  
  # remove the opposite sentiment variable, which we don't need any more
  select(-opp_sentiment2)

# Calculate sentiment of each bigram
bigrams_separated <- bigrams_separated %>%
  mutate(net_sentiment = (sentiment1 == 'positive') + (sentiment2 == 'positive') - 
           (sentiment1 == 'negative') - (sentiment2 == 'negative')) %>%
  unite(bigram, word1, word2, sep = ' ', remove = FALSE)
```

```{r Top 20 Positive Bigrams, message=FALSE, echo=FALSE}
bigrams_separated %>%
  filter(net_sentiment > 0) %>% # get positive bigrams
  count(bigram, sort = TRUE) %>%
  filter(rank(desc(n)) < 20) %>%
  ggplot(aes(reorder(bigram,n),n)) + geom_col(fill="slateblue3") + coord_flip() +
  labs(x = "", y="Count", title = "Top 20 Positive Bigrams")
```

```{r Top 20 Negative Bigrams, message=FALSE, echo=FALSE}
bigrams_separated %>%
  filter(net_sentiment < 0) %>% # get negative bigrams
  count(bigram, sort = TRUE) %>%
  filter(rank(desc(n)) < 20) %>%
  ggplot(aes(reorder(bigram,n),n)) + geom_col(fill="slateblue3") + coord_flip() +
  labs(x = "", y="Count", title = "Top 20 Negative Bigrams")
```

The findings illustrated in the plots partially align with what was observed in the top 20 positive and negative words. In the case of positive words and bigrams, several words appeared in both sets, such as **improve**, **support**, and **progress**. For the negative bigrams, the main themes were similar as before: **poverty**, **crime** and **corruption**. Interestingly, none of the negative bigrams contained negation words; these were subsequently extracted separately.

```{r Top 20 Bigrams with Negation, message=FALSE, echo=FALSE}
bigrams_separated %>%
  filter(net_sentiment < 0) %>% # get negative bigrams
  filter(word1 %in% negation_words) %>% # get bigrams where the first word is negation
  count(bigram, sort = TRUE) %>%
  arrange(desc(n)) %>% 
  head(20) %>%
  ggplot(aes(reorder(bigram, n), n)) + geom_col(fill="slateblue3") + coord_flip() +
  labs(x = "", y = "Count", title = "Top 20 Negative Bigrams with Negation Words")
```

The most frequently occuring negation words in the bigrams were **not** and **no**. Some sentences that include the "not enough" bigram are:

-   "But the response is that not enough criminals are being arrested and the quality of investigation is poor."

-   "Not enough jobs are being created."

-   "While structural reforms are necessary for us to revive economic growth, they are not enough on their own."

These examples highlight the importance of taking negation words into account as they reverse the sentiments of the sentences.

## LDA

As mentioned earlier, 9 topics were produced from the data. The 20 most used words can be seen in the figure below. ADD FIGURE While there is still some overlap among the topics, the general idea of these is fairly clear. The first topic seems to focus on a new democratic South Africa and the challenges this brings in the improvement on formerly oppressed bodies. Topic two mentions the words, 'crime', 'security', 'improve' and 'progress', which among many other words touches on the crime issues related to South Africa as well as the need progress as violent crimes have been prevalent in South Africa since the end of Apartheid. The third topic focusses on 'energy', 'infrastructure', 'health', 'water', 'mining' and 'women'. This may be a a nod to South Africa's water and energy infrastructure and development as well as the need to invest more in these plans and infrastructure to ensure consistent supply. 'Women' and 'children' which may be an indication of the vulnerability of these groups to the aformentioned issues or the need to include women in these sectors. Topic four looks at 'water' and 'infrastructure' again but also mentions 'cape', 'communities', 'rural' which may be referring to the Cape Town drought which occurred from 2015 - 2018 where rural areas were affected badly. Topic 5 looks at resource issues again but with focus on the economy and business and to provide support to them as the following words are mentioned: 'water', 'crisis', 'challenges', 'electricity', 'businesses', 'employment', 'support' and 'companies'.

Topic six mentions 'women', 'crisis', 'hope', 'improve' which may refer to the gender-based violence issue in South Africa which disproportionately affects women. Topic seven refers to a transition from an Apartheid South Africa to a democratic South Africa. Topic 8 contains 'billions', 'energy', 'support', 'commission', 'corruption' all which refer to South Africa's high corruption levels, especially in regards to the energy sector, more specifically ESKOM. Lastly, the ninth topic seems to focus on 'service' 'issues' and 'poverty' 'issues' which need to be addressed for the 'black' majority of South Africa who have been disproportionately been affected by poor service delivery and poverty due to the ramifications on Apartheid laws and poor initiative to uplift since then.

Overall, it was found that, per topic, Mandela and Ramaphosa appeared 7 times, Mbeki and Zuma 10 times and Motlanthe and de Klerk 1 time. This shows each presidents contribution to the topics.

Next, topic modelling was done for each president. While two topics we produced for each president, for those with a lower number of words, there was some overlap. Going chronologically, we start with de Klerk. de Klerk's first topic focussed on words such as 'freedom', 'constitution', 'peaceful', support' as well as 'zulu' which as true to the climate during the speech was in reference to the transitioning to a democratic and free South Africa. Zulu is mentioned as it was ensured in the constitution that the Zulu leaders be given a certain amount of political power as respect to the Zulu Kingdom. His second topic refers to 'election' and 'future' as this one is more focused on the future of South Africa and the move forward.

Mandela's first topic mentions 'progress', 'past', 'hope', 'improve', 'time', 'building', 'democracy' all of which are a related to improving the life of previously marginalized groups through a new, democratic state. His second topic focuses on many issues South Africa still faces such as crime and women's rights as well as security. Police is also mentioned in this topic as well as reconstruction. This topic may be related to the issues South Africa is facing and potential methods of change.

Mbeki's first topic addressed the need for improvement of services and infrastructure for local communities as well as some mention of international resources. The second topic looks at some of South Africa's issues such as 'poverty' and 'crime' and potential words that could be used to address these issues. 'Water' is also mentioned in this topic which could be an additional issue being addressed.

As Motlanthe only gave one speech, his topics are not very well defined. The first looks issues related to South Africa as well ways for improvement. While the second speaks to many things such as 'democracy', 'poverty' and 'children' too.

On the topic of water, Zuma's first topic mentions both 'water' and 'cape' as an indication of reference to the Cape Town droughts. It also mentions 'business', 'health' and 'education' all of which were sectors affected by this droughts. The topic also mentions 'job' and 'jobs' both of which may refer to the unemployment rates and promises of job creation. The second topic looks at resources such as 'electricity', 'water', 'energy' and also words such as 'support' and 'women'. This topic may be referring to the consistent supply of these resources and ways to ensure this while also focusing on support for women.

Lastly, the current president, Ramaphosa's, first topic is in relation to 'energy', 'eskom' and 'challenges' which is a nod to the energy issues South Africa is facing in relation to Eskom. 'Investment' and related words are mentioned implying this topic also includes the measures that are currently in place. 'Health' is also mentioned as well as 'capacity' which may be referring to the Covid-19 pandemic. The second topic mentions 'corruption' and 'electricity', 'investment' and related words which focusses on the corruption aspect of this issue.

## Trends

# Discussion

In this section, a sentiment analysis of the State of Nation Addresses was conducted to discern the overall feelings expressed by the South African presidents over time. It was discovered that most of the presidents, with the exception of deKlerk, had common interests: peace, freedom and progress. Recurring concerns were centered around poverty, crime and corruption. The analysis indicated that concerns over these themes did not change over time, as the logistic regression model indicated that the sentiment trend was consistent. It is worth noting that this analysis had some limitations, such as the under-representation of some presidents and the subjective nature of lexicons.

# Conclusions + how can we improve?

# References

Sadia et al (2018). <https://ieec.neduet.edu.pk/2018/Papers_2018/15.pdf>

> > > > > > > Stashed changes
